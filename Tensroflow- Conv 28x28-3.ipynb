{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data import Data\n",
    "from src.plothelp import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(\"img\")\n",
    "data.load_pickle(\"100x100.pickle \")\n",
    "data.resize_img((28,28)) \n",
    "X_train, X_test, y_train, y_test = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4698, 28, 28, 3) (522, 28, 28, 3) (4698,) (522,)\n"
     ]
    }
   ],
   "source": [
    "#Convert python lists to np arrays\n",
    "X_trains = np.asarray(X_train)\n",
    "X_tests = np.asarray(X_test)\n",
    "y_trains = np.asarray(y_train)\n",
    "y_tests = np.asarray(y_test)\n",
    "print(X_trains.shape, X_tests.shape, y_trains.shape, y_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_oh, y_test_oh= data.one_hot(y_trains, y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split y_train into 54 batches containing 87 img\n",
    "y_batch = np.array_split(y_oh, 54 )\n",
    "y_batch = np.asarray(y_batch)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split X_test into 54 batches of 87 img\n",
    "X_train_batch = np.array_split(X_trains, 54 )\n",
    "X_train_batch = np.asarray(X_train_batch)\n",
    "print(X_train_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 87\n",
    "n_epochs = 40\n",
    "keep_prob  = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 4  # first convolutional layer output depth\n",
    "l2 = 8  # second convolutional layer output depth\n",
    "l3 = 12  # third convolutional layer\n",
    "l4 = 200  # fully connected layer\n",
    "num_classes = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal([5, 5, 3, l1], stddev=0.1))  # 5x5 patch, 3 input channel, K output channels\n",
    "b1 = tf.Variable(tf.random_normal([l1]))\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([5, 5, l1, l2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.random_normal([l2]))\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([4, 4, l2, l3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.random_normal([l3]))\n",
    "\n",
    "w4 = tf.Variable(tf.truncated_normal([7 * 7 * l3, l4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.random_normal([l4]))\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([l4, num_classes], stddev=0.1))\n",
    "b = tf.Variable(tf.random_normal([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, w1, strides=[1, 1, 1, 1], padding='SAME') + b1)\n",
    "Y1 = tf.nn.dropout(Y1,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "Y2 = tf.nn.conv2d(Y1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y2 = tf.nn.max_pool(Y2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 14x14\n",
    "Y2 = tf.nn.relu( Y2+ b2)\n",
    "Y2 = tf.nn.dropout(Y2,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "Y3 = tf.nn.conv2d(Y2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y3 = tf.nn.max_pool(Y3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 7x7\n",
    "Y3 = tf.nn.relu(Y3+ b3)\n",
    "Y3 = tf.nn.dropout(Y3,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "# fully connected layer\n",
    "fc = tf.reshape(Y3, shape=[-1, 7 * 7 * l3])\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(fc, w4) + b4)\n",
    "Y4 = tf.nn.dropout(Y4,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "Ylogits = tf.matmul(Y4, w) + b\n",
    "logits = tf.nn.softmax(Ylogits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 accuracy= 0.260962111\n",
      "Epoch: 0002 accuracy= 0.255002129\n",
      "Epoch: 0003 accuracy= 0.252234993\n",
      "Epoch: 0004 accuracy= 0.247339293\n",
      "Epoch: 0005 accuracy= 0.256704982\n",
      "Epoch: 0006 accuracy= 0.257556408\n",
      "Epoch: 0007 accuracy= 0.260962112\n",
      "Epoch: 0008 accuracy= 0.261600680\n",
      "Epoch: 0009 accuracy= 0.270327801\n",
      "Epoch: 0010 accuracy= 0.271179225\n",
      "Epoch: 0011 accuracy= 0.275436357\n",
      "Epoch: 0012 accuracy= 0.279693488\n",
      "Epoch: 0013 accuracy= 0.282460624\n",
      "Epoch: 0014 accuracy= 0.281183482\n",
      "Epoch: 0015 accuracy= 0.278842060\n",
      "Epoch: 0016 accuracy= 0.286717751\n",
      "Epoch: 0017 accuracy= 0.288846319\n",
      "Epoch: 0018 accuracy= 0.298637720\n",
      "Epoch: 0019 accuracy= 0.291613452\n",
      "Epoch: 0020 accuracy= 0.294593443\n",
      "Epoch: 0021 accuracy= 0.290974884\n",
      "Epoch: 0022 accuracy= 0.296509154\n",
      "Epoch: 0023 accuracy= 0.304597703\n",
      "Epoch: 0024 accuracy= 0.309706257\n",
      "Epoch: 0025 accuracy= 0.301191994\n",
      "Epoch: 0026 accuracy= 0.308216263\n",
      "Epoch: 0027 accuracy= 0.302469136\n",
      "Epoch: 0028 accuracy= 0.312260536\n",
      "Epoch: 0029 accuracy= 0.314814816\n",
      "Epoch: 0030 accuracy= 0.310983398\n",
      "Epoch: 0031 accuracy= 0.325031928\n",
      "Epoch: 0032 accuracy= 0.327160494\n",
      "Epoch: 0033 accuracy= 0.319497658\n",
      "Epoch: 0034 accuracy= 0.315879099\n",
      "Epoch: 0035 accuracy= 0.316943382\n",
      "Epoch: 0036 accuracy= 0.316304810\n",
      "Epoch: 0037 accuracy= 0.322690508\n",
      "Epoch: 0038 accuracy= 0.335249043\n",
      "Epoch: 0039 accuracy= 0.331417624\n",
      "Epoch: 0040 accuracy= 0.338441891\n",
      "Epoch: 0041 accuracy= 0.348446148\n",
      "Epoch: 0042 accuracy= 0.343763304\n",
      "Epoch: 0043 accuracy= 0.349084718\n",
      "Epoch: 0044 accuracy= 0.341209026\n",
      "Epoch: 0045 accuracy= 0.344827585\n",
      "Epoch: 0046 accuracy= 0.349510429\n",
      "Epoch: 0047 accuracy= 0.346956152\n",
      "Epoch: 0048 accuracy= 0.349936144\n",
      "Epoch: 0049 accuracy= 0.360578970\n",
      "Epoch: 0050 accuracy= 0.354406132\n",
      "Epoch: 0051 accuracy= 0.369518944\n",
      "Epoch: 0052 accuracy= 0.350361856\n",
      "Epoch: 0053 accuracy= 0.357598980\n",
      "Epoch: 0054 accuracy= 0.365474669\n",
      "Epoch: 0055 accuracy= 0.371647509\n",
      "Epoch: 0056 accuracy= 0.373137506\n",
      "Epoch: 0057 accuracy= 0.391868881\n",
      "Epoch: 0058 accuracy= 0.390591741\n",
      "Epoch: 0059 accuracy= 0.389527462\n",
      "Epoch: 0060 accuracy= 0.414431672\n",
      "Epoch: 0061 accuracy= 0.478501487\n",
      "Epoch: 0062 accuracy= 0.483397186\n",
      "Epoch: 0063 accuracy= 0.502341419\n",
      "Epoch: 0064 accuracy= 0.522137078\n",
      "Epoch: 0065 accuracy= 0.522137078\n",
      "Epoch: 0066 accuracy= 0.529161342\n",
      "Epoch: 0067 accuracy= 0.533631330\n",
      "Epoch: 0068 accuracy= 0.504469987\n",
      "Epoch: 0069 accuracy= 0.540655595\n",
      "Epoch: 0070 accuracy= 0.548105578\n",
      "Epoch: 0071 accuracy= 0.556194122\n",
      "Epoch: 0072 accuracy= 0.551936996\n",
      "Epoch: 0073 accuracy= 0.568114090\n",
      "Epoch: 0074 accuracy= 0.560238394\n",
      "Epoch: 0075 accuracy= 0.571306938\n",
      "Epoch: 0076 accuracy= 0.572584076\n",
      "Epoch: 0077 accuracy= 0.574925500\n",
      "Epoch: 0078 accuracy= 0.571094082\n",
      "Epoch: 0079 accuracy= 0.574286923\n",
      "Epoch: 0080 accuracy= 0.584929754\n",
      "Epoch: 0081 accuracy= 0.575564069\n",
      "Epoch: 0082 accuracy= 0.580885481\n",
      "Epoch: 0083 accuracy= 0.590038312\n",
      "Epoch: 0084 accuracy= 0.569816943\n",
      "Epoch: 0085 accuracy= 0.585568330\n",
      "Epoch: 0086 accuracy= 0.575564070\n",
      "Epoch: 0087 accuracy= 0.591528309\n",
      "Epoch: 0088 accuracy= 0.571306935\n",
      "Epoch: 0089 accuracy= 0.589825458\n",
      "Epoch: 0090 accuracy= 0.596211154\n",
      "Epoch: 0091 accuracy= 0.598339717\n",
      "Epoch: 0092 accuracy= 0.589825461\n",
      "Epoch: 0093 accuracy= 0.594082587\n",
      "Epoch: 0094 accuracy= 0.608556831\n",
      "Epoch: 0095 accuracy= 0.606002550\n",
      "Epoch: 0096 accuracy= 0.606002552\n",
      "Epoch: 0097 accuracy= 0.601745423\n",
      "Epoch: 0098 accuracy= 0.601319711\n",
      "Epoch: 0099 accuracy= 0.608769689\n",
      "Epoch: 0100 accuracy= 0.613239671\n",
      "Model saved in file: ./models/conv28x28x3-drop70.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    n_batches = 54\n",
    "    for epochs in range(100):\n",
    "        acc = 0\n",
    "        for i in range(n_batches):\n",
    "            batch_X = X_train_batch[i, :]\n",
    "            batch_Y = y_batch[i, :]\n",
    "            _, a = sess.run([train_step, accuracy], {X: batch_X, Y: batch_Y})\n",
    "            acc=acc+a\n",
    "        print(\"Epoch:\", '%04d' % (epochs + 1), \"accuracy=\", \"{:.9f}\".format(acc/54))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./models/conv28x28x3-drop70.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "0.578544\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver().restore(sess, \"./models/conv28x28x3-drop70.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(sess.run(accuracy, feed_dict={X: X_tests, Y: y_test_oh}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional neural network with 3 convlutional layers and one fully connected layer. It achieved very high accuracy while training on the dataset. However, tested model achieved only 36.6 % accuracy. Hypothesis why training accuracy is so high while test accuracy is low is that the learnt model overfits the training data. The other possibility is that neural network is not deep enought and needs more layers. Adding a dropout for neurons should improve the classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
