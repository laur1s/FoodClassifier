{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data import Data\n",
    "from src.plothelp import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Data(\"img\")\n",
    "data.load_pickle(\"100x100.pickle \")\n",
    "X_train, X_test, y_train, y_test = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4698, 30000) (522, 30000) (4698,) (522,)\n"
     ]
    }
   ],
   "source": [
    "X_trains = np.asarray(X_train).reshape((len(X_train), -1))\n",
    "X_tests = np.asarray(X_test).reshape((len(X_test), -1))\n",
    "y_trains = np.asarray(y_train)\n",
    "y_tests = np.asarray(y_test)\n",
    "print(X_trains.shape, X_tests.shape, y_trains.shape, y_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_oh, y_test_oh= data.one_hot(y_trains, y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split y_train into 54 batches containing 87 img\n",
    "y_batch = np.array_split(y_oh, 54 )\n",
    "y_batch = np.asarray(y_batch)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 30000)\n",
      "(54, 87, 30000)\n"
     ]
    }
   ],
   "source": [
    "# Split X_test into 54 batches of 87 img\n",
    "X_train_batch = np.array_split(X_trains, 54 )\n",
    "X_train_batch = np.asarray(X_train_batch)\n",
    "print(X_train_batch.shape)\n",
    "print(X_train_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "batch_size = 87\n",
    "n_epochs = 30\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 30000])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of neurons in layers\n",
    "in_n = 30000 #input layer\n",
    "l2 = 256  #layer 2\n",
    "l3 = 256  #layer 3\n",
    "final = 4 #final layer\n",
    "\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal(shape=[in_n, l2], stddev=0.01))\n",
    "b1 = tf.Variable(tf.random_normal([l2]))\n",
    "w2 = tf.Variable(tf.truncated_normal([l2, l3], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([l3]))\n",
    "w3 = tf.Variable(tf.truncated_normal([l3, final], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([final]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The network model\n",
    "y1 = tf.nn.relu(tf.matmul(X, w1) + b1)\n",
    "#y1 = tf.nn.dropout(y1,dropout)\n",
    "y2 = tf.nn.relu(tf.matmul(y1, w2) + b2)\n",
    "#y2 = tf.nn.dropout(y2,dropout)\n",
    "logits = tf.matmul(y2, w3) + b3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "acc = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
    "  \n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 cost= 2.55071395194 accuracy= 0.357598980268\n",
      "Epoch: 002 cost= 1.16828697478 accuracy= 0.468922946188\n",
      "Epoch: 003 cost= 1.1157141372 accuracy= 0.509578542577\n",
      "Epoch: 004 cost= 1.07089120039 accuracy= 0.536824177813\n",
      "Epoch: 005 cost= 1.0367806598 accuracy= 0.563005535139\n",
      "Epoch: 006 cost= 1.0016512926 accuracy= 0.590251167615\n",
      "Epoch: 007 cost= 0.99519857102 accuracy= 0.593656870502\n",
      "Epoch: 008 cost= 0.964340439549 accuracy= 0.604725417164\n",
      "Epoch: 009 cost= 0.943649695979 accuracy= 0.619838230588\n",
      "Epoch: 010 cost= 0.924821168184 accuracy= 0.629416770405\n",
      "Epoch: 011 cost= 0.896670351426 accuracy= 0.648786714783\n",
      "Epoch: 012 cost= 0.899215035968 accuracy= 0.64410387697\n",
      "Epoch: 013 cost= 0.883694005233 accuracy= 0.641762455304\n",
      "Epoch: 014 cost= 0.879168560108 accuracy= 0.647722437978\n",
      "Epoch: 015 cost= 0.884021762345 accuracy= 0.642613875093\n",
      "Epoch: 016 cost= 0.820838715191 accuracy= 0.681566629145\n",
      "Epoch: 017 cost= 0.856995729385 accuracy= 0.659855257582\n",
      "Epoch: 018 cost= 0.818622213823 accuracy= 0.681140907385\n",
      "Epoch: 019 cost= 0.781524093063 accuracy= 0.694338018144\n",
      "Epoch: 020 cost= 0.763390001323 accuracy= 0.706470839403\n",
      "Epoch: 021 cost= 0.748693790701 accuracy= 0.710515112789\n",
      "Epoch: 022 cost= 0.720854430287 accuracy= 0.725202210523\n",
      "Epoch: 023 cost= 0.69284045917 accuracy= 0.745849293691\n",
      "Epoch: 024 cost= 0.690798555259 accuracy= 0.739463601951\n",
      "Epoch: 025 cost= 0.672575609552 accuracy= 0.748829286408\n",
      "Epoch: 026 cost= 0.64277079867 accuracy= 0.767347808237\n",
      "Epoch: 027 cost= 0.628353001343 accuracy= 0.768837800732\n",
      "Epoch: 028 cost= 0.640023135477 accuracy= 0.763516390765\n",
      "Epoch: 029 cost= 0.61464476751 accuracy= 0.773733503289\n",
      "Epoch: 030 cost= 0.596191247304 accuracy= 0.778416345517\n",
      "Model saved in file: ./models/3layer-lr=0.0001.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  batch_img = 54\n",
    "  for i in range(n_epochs):  # train the model n_epochs times\n",
    "        avg_acc = 0.\n",
    "        avg_cost = 0.\n",
    "        \n",
    "        for j in range(batch_img):\n",
    "            X_batch = X_train_batch[j,:]\n",
    "            Y_batch = y_batch[j,:]\n",
    "            _,c, a =sess.run([optimizer, loss, acc], feed_dict={X: X_batch, Y: Y_batch})\n",
    "            avg_acc += a/batch_img\n",
    "            avg_cost += c / batch_img\n",
    "            \n",
    "        print(\"Epoch:\", '%03d' % (i+1), \"cost=\", avg_cost, \"accuracy=\",avg_acc)\n",
    "            \n",
    "            \n",
    "  save_path = saver.save(sess, \"./models/3layer-lr=0.0001.ckpt\")\n",
    "  print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "Accuracy 0.5632183908045977\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  saver.restore(sess, \"./models/3layer-lr=0.0001.ckpt\")\n",
    "  print(\"Model restored.\")\n",
    "  \n",
    "  _, loss_batch, logits_batch = sess.run([optimizer, loss, logits],\n",
    "                                         feed_dict={X: X_tests, Y: y_test_oh})\n",
    "  preds = tf.nn.softmax(logits_batch)\n",
    "  correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(y_test_oh, 1))\n",
    "  accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "  pred_acc = sess.run(accuracy)\n",
    "  print (\"Accuracy {0}\".format(pred_acc / 522))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
