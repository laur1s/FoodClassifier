{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data import Data\n",
    "from src.plothelp import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(\"img\")\n",
    "data.load_pickle(\"100x100.pickle \")\n",
    "data.resize_img((56,56)) \n",
    "X_train, X_test, y_train, y_test = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4698, 56, 56, 3) (522, 56, 56, 3) (4698,) (522,)\n"
     ]
    }
   ],
   "source": [
    "#Convert python lists to np arrays\n",
    "X_trains = np.asarray(X_train)\n",
    "X_tests = np.asarray(X_test)\n",
    "y_trains = np.asarray(y_train)\n",
    "y_tests = np.asarray(y_test)\n",
    "print(X_trains.shape, X_tests.shape, y_trains.shape, y_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_oh, y_test_oh= data.one_hot(y_trains, y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split y_train into 54 batches containing 87 img\n",
    "y_batch = np.array_split(y_oh, 54 )\n",
    "y_batch = np.asarray(y_batch)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 56, 56, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split X_test into 54 batches of 87 img\n",
    "X_train_batch = np.array_split(X_trains, 54 )\n",
    "X_train_batch = np.asarray(X_train_batch)\n",
    "print(X_train_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 87\n",
    "n_epochs = 100\n",
    "keep_prob  = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images\n",
    "X = tf.placeholder(tf.float32, [None, 56, 56, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 4  # first convolutional layer output depth\n",
    "l2 = 8  # second convolutional layer output depth\n",
    "l3 = 12  # third convolutional layer\n",
    "l4 = 12  # forth conv\n",
    "l5 = 200  # fully connected layer\n",
    "num_classes = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal([5, 5, 3, l1], stddev=0.1))  # 5x5 patch, 3 input channel, K output channels\n",
    "b1 = tf.Variable(tf.random_normal([l1]))\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([5, 5, l1, l2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.random_normal([l2]))\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([4, 4, l2, l3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.random_normal([l3]))\n",
    "\n",
    "w4 = tf.Variable(tf.truncated_normal([4, 4, l3,l4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.random_normal([l4]))\n",
    "\n",
    "w5 = tf.Variable(tf.truncated_normal([7 * 7 * l4, l5], stddev=0.1))\n",
    "b5 = tf.Variable(tf.random_normal([l5]))\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([l5, num_classes], stddev=0.1))\n",
    "b = tf.Variable(tf.random_normal([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, w1, strides=[1, 1, 1, 1], padding='SAME') + b1)\n",
    "Y1 = tf.nn.dropout(Y1,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "Y2 = tf.nn.conv2d(Y1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y2 = tf.nn.max_pool(Y2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 28x28\n",
    "Y2 = tf.nn.relu( Y2+ b2)\n",
    "Y2 = tf.nn.dropout(Y2,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "Y3 = tf.nn.conv2d(Y2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y3 = tf.nn.max_pool(Y3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 14x14\n",
    "Y3 = tf.nn.relu(Y3+ b3)\n",
    "Y3 = tf.nn.dropout(Y3,keep_prob=keep_prob) #for adding dropout, comment to disable\n",
    "\n",
    "Y4 = tf.nn.conv2d(Y3, w4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y4 = tf.nn.max_pool(Y3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 7x7\n",
    "Y4 = tf.nn.relu(Y4+ b4)\n",
    "Y4 = tf.nn.dropout(Y4,keep_prob=keep_prob)\n",
    "\n",
    "# fully connected layer\n",
    "fc = tf.reshape(Y4, shape=[-1, 7 * 7 * l4])\n",
    "\n",
    "Y5 = tf.nn.relu(tf.matmul(fc, w5) + b5)\n",
    "Y5 = tf.nn.dropout(Y5,keep_prob=keep_prob)\n",
    "Ylogits = tf.matmul(Y5, w) + b\n",
    "logits = tf.nn.softmax(Ylogits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 accuracy= 0.282673479\n",
      "Epoch: 0002 accuracy= 0.276926354\n",
      "Epoch: 0003 accuracy= 0.288846318\n",
      "Epoch: 0004 accuracy= 0.296509154\n",
      "Epoch: 0005 accuracy= 0.347807579\n",
      "Epoch: 0006 accuracy= 0.371647508\n",
      "Epoch: 0007 accuracy= 0.379736058\n",
      "Epoch: 0008 accuracy= 0.395274587\n",
      "Epoch: 0009 accuracy= 0.394210302\n",
      "Epoch: 0010 accuracy= 0.398254576\n",
      "Epoch: 0011 accuracy= 0.412515964\n",
      "Epoch: 0012 accuracy= 0.415283098\n",
      "Epoch: 0013 accuracy= 0.431673052\n",
      "Epoch: 0014 accuracy= 0.422307365\n",
      "Epoch: 0015 accuracy= 0.426777352\n",
      "Epoch: 0016 accuracy= 0.438484460\n",
      "Epoch: 0017 accuracy= 0.439974457\n",
      "Epoch: 0018 accuracy= 0.458492976\n",
      "Epoch: 0019 accuracy= 0.475521496\n",
      "Epoch: 0020 accuracy= 0.473180077\n",
      "Epoch: 0021 accuracy= 0.473392930\n",
      "Epoch: 0022 accuracy= 0.481268622\n",
      "Epoch: 0023 accuracy= 0.485738608\n",
      "Epoch: 0024 accuracy= 0.494678585\n",
      "Epoch: 0025 accuracy= 0.493614299\n",
      "Epoch: 0026 accuracy= 0.509578539\n",
      "Epoch: 0027 accuracy= 0.522775649\n",
      "Epoch: 0028 accuracy= 0.515325667\n",
      "Epoch: 0029 accuracy= 0.516602805\n",
      "Epoch: 0030 accuracy= 0.529161344\n",
      "Epoch: 0031 accuracy= 0.517241374\n",
      "Epoch: 0032 accuracy= 0.514261389\n",
      "Epoch: 0033 accuracy= 0.525755641\n",
      "Epoch: 0034 accuracy= 0.538101318\n",
      "Epoch: 0035 accuracy= 0.546402723\n",
      "Epoch: 0036 accuracy= 0.545338438\n",
      "Epoch: 0037 accuracy= 0.558535547\n",
      "Epoch: 0038 accuracy= 0.549808427\n",
      "Epoch: 0039 accuracy= 0.563431243\n",
      "Epoch: 0040 accuracy= 0.558961258\n",
      "Epoch: 0041 accuracy= 0.570881225\n",
      "Epoch: 0042 accuracy= 0.563431241\n",
      "Epoch: 0043 accuracy= 0.580034056\n",
      "Epoch: 0044 accuracy= 0.584291185\n",
      "Epoch: 0045 accuracy= 0.584504046\n",
      "Epoch: 0046 accuracy= 0.580885482\n",
      "Epoch: 0047 accuracy= 0.591528307\n",
      "Epoch: 0048 accuracy= 0.607705408\n",
      "Epoch: 0049 accuracy= 0.591102593\n",
      "Epoch: 0050 accuracy= 0.613665389\n",
      "Epoch: 0051 accuracy= 0.601745419\n",
      "Epoch: 0052 accuracy= 0.622818221\n",
      "Epoch: 0053 accuracy= 0.617922519\n",
      "Epoch: 0054 accuracy= 0.636866749\n",
      "Epoch: 0055 accuracy= 0.633248193\n",
      "Epoch: 0056 accuracy= 0.658152403\n",
      "Epoch: 0057 accuracy= 0.657088124\n",
      "Epoch: 0058 accuracy= 0.664538100\n",
      "Epoch: 0059 accuracy= 0.676883780\n",
      "Epoch: 0060 accuracy= 0.682205196\n",
      "Epoch: 0061 accuracy= 0.681353762\n",
      "Epoch: 0062 accuracy= 0.703065136\n",
      "Epoch: 0063 accuracy= 0.707747976\n",
      "Epoch: 0064 accuracy= 0.716687953\n",
      "Epoch: 0065 accuracy= 0.704980842\n",
      "Epoch: 0066 accuracy= 0.720306513\n",
      "Epoch: 0067 accuracy= 0.709450825\n",
      "Epoch: 0068 accuracy= 0.732013619\n",
      "Epoch: 0069 accuracy= 0.728607916\n",
      "Epoch: 0070 accuracy= 0.721796508\n",
      "Epoch: 0071 accuracy= 0.734567902\n",
      "Epoch: 0072 accuracy= 0.729033632\n",
      "Epoch: 0073 accuracy= 0.734355045\n",
      "Epoch: 0074 accuracy= 0.723499358\n",
      "Epoch: 0075 accuracy= 0.727543633\n",
      "Epoch: 0076 accuracy= 0.728820775\n",
      "Epoch: 0077 accuracy= 0.744997869\n",
      "Epoch: 0078 accuracy= 0.747552145\n",
      "Epoch: 0079 accuracy= 0.738186461\n",
      "Epoch: 0080 accuracy= 0.744785014\n",
      "Epoch: 0081 accuracy= 0.737122179\n",
      "Epoch: 0082 accuracy= 0.756066407\n",
      "Epoch: 0083 accuracy= 0.746275006\n",
      "Epoch: 0084 accuracy= 0.756917836\n",
      "Epoch: 0085 accuracy= 0.749254998\n",
      "Epoch: 0086 accuracy= 0.753512131\n",
      "Epoch: 0087 accuracy= 0.756704978\n",
      "Epoch: 0088 accuracy= 0.758407833\n",
      "Epoch: 0089 accuracy= 0.761813539\n",
      "Epoch: 0090 accuracy= 0.756704979\n",
      "Epoch: 0091 accuracy= 0.760323539\n",
      "Epoch: 0092 accuracy= 0.770327799\n",
      "Epoch: 0093 accuracy= 0.759259258\n",
      "Epoch: 0094 accuracy= 0.766070668\n",
      "Epoch: 0095 accuracy= 0.763303534\n",
      "Epoch: 0096 accuracy= 0.770114941\n",
      "Epoch: 0097 accuracy= 0.772882083\n",
      "Epoch: 0098 accuracy= 0.768624950\n",
      "Epoch: 0099 accuracy= 0.765006384\n",
      "Epoch: 0100 accuracy= 0.757556403\n",
      "Model saved in file: ./models/conv56x56x3-drop-100iter0.008.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    n_batches = 54\n",
    "    for epochs in range(100):\n",
    "        acc = 0\n",
    "        for i in range(n_batches):\n",
    "            batch_X = X_train_batch[i, :]\n",
    "            batch_Y = y_batch[i, :]\n",
    "            _, a = sess.run([train_step, accuracy], {X: batch_X, Y: batch_Y})\n",
    "            acc=acc+a\n",
    "        print(\"Epoch:\", '%04d' % (epochs + 1), \"accuracy=\", \"{:.9f}\".format(acc/54))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./models/conv56x56x3-drop-100.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "0.693487\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver().restore(sess, \"./models/conv56x56x3-drop-100.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(sess.run(accuracy, feed_dict={X: X_tests, Y: y_test_oh}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
