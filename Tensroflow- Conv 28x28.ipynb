{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.data import Data\n",
    "from src.plothelp import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and pre-process the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(\"img\")\n",
    "data.load_pickle(\"28x28.pickle \")\n",
    "X_train, X_test, y_train, y_test = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4698, 28, 28) (522, 28, 28) (4698,) (522,)\n"
     ]
    }
   ],
   "source": [
    "#Convert python lists to np arrays\n",
    "X_trains = np.asarray(X_train)\n",
    "X_tests = np.asarray(X_test)\n",
    "y_trains = np.asarray(y_train)\n",
    "y_tests = np.asarray(y_test)\n",
    "print(X_trains.shape, X_tests.shape, y_trains.shape, y_tests.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_oh, y_test_oh= data.one_hot(y_trains, y_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split y_train into 54 batches containing 87 img\n",
    "y_batch = np.array_split(y_oh, 54 )\n",
    "y_batch = np.asarray(y_batch)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 87, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split X_test into 54 batches of 87 img\n",
    "X_train_batch = np.array_split(X_trains, 54 )\n",
    "X_train_batch = np.asarray(X_train_batch)\n",
    "X_train_batch = np.expand_dims(X_train_batch, axis=-1)\n",
    "print(X_train_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tests = np.expand_dims(X_tests, axis=3)\n",
    "X_tests.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "batch_size = 87\n",
    "n_epochs = 40\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = 4  # first convolutional layer output depth\n",
    "l2 = 8  # second convolutional layer output depth\n",
    "l3 = 12  # third convolutional layer\n",
    "l4 = 200  # fully connected layer\n",
    "num_classes = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.truncated_normal([5, 5, 1, l1], stddev=0.1))  # 5x5 patch, 1 input channel, K output channels\n",
    "b1 = tf.Variable(tf.random_normal([l1]))\n",
    "\n",
    "w2 = tf.Variable(tf.truncated_normal([5, 5, l1, l2], stddev=0.1))\n",
    "b2 = tf.Variable(tf.random_normal([l2]))\n",
    "\n",
    "w3 = tf.Variable(tf.truncated_normal([4, 4, l2, l3], stddev=0.1))\n",
    "b3 = tf.Variable(tf.random_normal([l3]))\n",
    "\n",
    "w4 = tf.Variable(tf.truncated_normal([7 * 7 * l3, l4], stddev=0.1))\n",
    "b4 = tf.Variable(tf.random_normal([l4]))\n",
    "\n",
    "w = tf.Variable(tf.truncated_normal([l4, num_classes], stddev=0.1))\n",
    "b = tf.Variable(tf.random_normal([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The model\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, w1, strides=[1, 1, 1, 1], padding='SAME') + b1)\n",
    "\n",
    "Y2 = tf.nn.conv2d(Y1, w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y2 = tf.nn.max_pool(Y2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 14x14\n",
    "Y2 = tf.nn.relu( Y2+ b2)\n",
    "\n",
    "Y3 = tf.nn.conv2d(Y2, w3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "Y3 = tf.nn.max_pool(Y3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding='SAME')  # reduce to 7x7\n",
    "Y3 = tf.nn.relu(Y3+ b3)\n",
    "\n",
    "# fully connected layer\n",
    "fc = tf.reshape(Y3, shape=[-1, 7 * 7 * l3])\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(fc, w4) + b4)\n",
    "Ylogits = tf.matmul(Y4, w) + b\n",
    "logits = tf.nn.softmax(Ylogits)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 accuracy= 0.263516390\n",
      "Epoch: 0002 accuracy= 0.326309071\n",
      "Epoch: 0003 accuracy= 0.371434653\n",
      "Epoch: 0004 accuracy= 0.422094507\n",
      "Epoch: 0005 accuracy= 0.469774370\n",
      "Epoch: 0006 accuracy= 0.537462751\n",
      "Epoch: 0007 accuracy= 0.583439759\n",
      "Epoch: 0008 accuracy= 0.601958280\n",
      "Epoch: 0009 accuracy= 0.625159641\n",
      "Epoch: 0010 accuracy= 0.620689657\n",
      "Epoch: 0011 accuracy= 0.656662408\n",
      "Epoch: 0012 accuracy= 0.625798213\n",
      "Epoch: 0013 accuracy= 0.684972330\n",
      "Epoch: 0014 accuracy= 0.729246489\n",
      "Epoch: 0015 accuracy= 0.769476373\n",
      "Epoch: 0016 accuracy= 0.710727969\n",
      "Epoch: 0017 accuracy= 0.730097912\n",
      "Epoch: 0018 accuracy= 0.738612178\n",
      "Epoch: 0019 accuracy= 0.690080880\n",
      "Epoch: 0020 accuracy= 0.815666236\n",
      "Epoch: 0021 accuracy= 0.862494678\n",
      "Epoch: 0022 accuracy= 0.797999146\n",
      "Epoch: 0023 accuracy= 0.754789272\n",
      "Epoch: 0024 accuracy= 0.767773521\n",
      "Epoch: 0025 accuracy= 0.770540657\n",
      "Epoch: 0026 accuracy= 0.803959131\n",
      "Epoch: 0027 accuracy= 0.859301824\n",
      "Epoch: 0028 accuracy= 0.858237545\n",
      "Epoch: 0029 accuracy= 0.872073220\n",
      "Epoch: 0030 accuracy= 0.884418901\n",
      "Epoch: 0031 accuracy= 0.886121750\n",
      "Epoch: 0032 accuracy= 0.886760329\n",
      "Epoch: 0033 accuracy= 0.916347380\n",
      "Epoch: 0034 accuracy= 0.926564490\n",
      "Epoch: 0035 accuracy= 0.913367385\n",
      "Epoch: 0036 accuracy= 0.898254571\n",
      "Epoch: 0037 accuracy= 0.899531712\n",
      "Epoch: 0038 accuracy= 0.923371652\n",
      "Epoch: 0039 accuracy= 0.939761600\n",
      "Epoch: 0040 accuracy= 0.947424437\n",
      "Epoch: 0041 accuracy= 0.957002976\n",
      "Epoch: 0042 accuracy= 0.973180073\n",
      "Epoch: 0043 accuracy= 0.977224343\n",
      "Epoch: 0044 accuracy= 0.984248607\n",
      "Epoch: 0045 accuracy= 0.983184325\n",
      "Epoch: 0046 accuracy= 0.980842902\n",
      "Epoch: 0047 accuracy= 0.977862914\n",
      "Epoch: 0048 accuracy= 0.974670067\n",
      "Epoch: 0049 accuracy= 0.981694332\n",
      "Epoch: 0050 accuracy= 0.983184328\n",
      "Epoch: 0051 accuracy= 0.984035751\n",
      "Epoch: 0052 accuracy= 0.984035752\n",
      "Epoch: 0053 accuracy= 0.978714339\n",
      "Epoch: 0054 accuracy= 0.984674320\n",
      "Epoch: 0055 accuracy= 0.981694330\n",
      "Epoch: 0056 accuracy= 0.982332897\n",
      "Epoch: 0057 accuracy= 0.970200079\n",
      "Epoch: 0058 accuracy= 0.967007230\n",
      "Epoch: 0059 accuracy= 0.973818640\n",
      "Epoch: 0060 accuracy= 0.971264366\n",
      "Epoch: 0061 accuracy= 0.977011490\n",
      "Epoch: 0062 accuracy= 0.976585776\n",
      "Epoch: 0063 accuracy= 0.965304380\n",
      "Epoch: 0064 accuracy= 0.973818638\n",
      "Epoch: 0065 accuracy= 0.980630050\n",
      "Epoch: 0066 accuracy= 0.985100034\n",
      "Epoch: 0067 accuracy= 0.975734352\n",
      "Epoch: 0068 accuracy= 0.976372917\n",
      "Model saved in file: ./models/conv28x28-2.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    n_batches = 54\n",
    "    for epochs in range(68):\n",
    "        acc = 0\n",
    "        for i in range(n_batches):\n",
    "            batch_X = X_train_batch[i, :]\n",
    "            batch_Y = y_batch[i, :]\n",
    "            _, a = sess.run([train_step, accuracy], {X: batch_X, Y: batch_Y})\n",
    "            acc=acc+a\n",
    "        print(\"Epoch:\", '%04d' % (epochs + 1), \"accuracy=\", \"{:.9f}\".format(acc/54))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./models/conv28x28-2.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n",
      "0.381226\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver().restore(sess, \"./models/conv28x28-2.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(sess.run(accuracy, feed_dict={X: X_tests, Y: y_test_oh}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional neural network with 3 convlutional layers and one fully connected layer. It achieved very high accuracy while training on the dataset. However, tested model achieved only 38.12 % accuracy. Hypothesis why training accuracy is so high while test accuracy is low is that the learnt model overfits the training data. The other possibility is that neural network is not deep enought and needs more layers. Adding a dropout for neurons should improve the classifier. The model was saved as conv28x28-2.ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
